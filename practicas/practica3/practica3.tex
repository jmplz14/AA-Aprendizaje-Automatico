
\documentclass[titlepage]{article}
 \usepackage[utf8]{inputenc}
\usepackage{listings}
\usepackage{float}
\usepackage{graphicx}
\usepackage{subfig}
\graphicspath{ {imagenes/} }
 \usepackage{xcolor}
 \definecolor{RoyalBlue}{cmyk}{1, 0.50, 0, 0}

\lstset{language=Java,
	keywordstyle=\color{RoyalBlue},
	basicstyle=\scriptsize\ttfamily,
	commentstyle=\ttfamily\itshape\color{gray},
	stringstyle=\ttfamily,
	showstringspaces=false,
	breaklines=true,
	frameround=ffff,
	frame=single,
	rulecolor=\color{black}}


 

% Datos de la portada
\begin{document}
	\begin{titlepage}
		\begin{center}
			\vspace*{1cm}
			\date{} % para que no aparezca la fecha la dejo en blanco
			\Huge
			\textbf{Practica 3}
			
			\vspace{0.5cm}
			\LARGE
			Aprendizaje Automático
			
			\vspace{1.5cm}
			
			\textbf{José Manuel Pérez Lendínez}
			

			
		\end{center}
	\newpage
	\tableofcontents
	\newpage
	\end{titlepage}

	\section{Digits Data Set}	
	\subsection{Comprender el problema a resolver.}
	Los datos almacenados en el dataset pertenecen a un conjunto de dígitos manuscritos. 
	Para el reconocimiento de los dígitos se utiliza una matriz de 32x32 inicialmente. Esta matriz se dividirá en matrices mas pequeñas de 4x4 sin solaparse. A cada una de estas matrices le daremos un valor numérico en el rango [0,16].
	Vamos a poner un pequeño ejemplo. La matriz inicial 32x32 seria la siguiente.
\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\linewidth, height=0.72\textheight]{4}

\end{figure}
	Como se ve los 0 representa la parte sin utilizar y los 1 la parte donde se escribe. 
	\newpage
	Esta matriz se divide en pequeñas matices 4x4 como en la siguiente imagen.
	\begin{figure}[H]
		\centering
			\includegraphics[width=0.7\linewidth, height=0.72\textheight]{4matriculado}

	\end{figure}
	\newpage
	En cada matriz 4x4 contaremos el numero de 1 que tenemos y le daremos ese valor. Vamos a realizar esto con la quinta fila para ver un ejemplo. 
	\begin{figure}[H]
		\centering
		\includegraphics[width=0.7\linewidth]{columanasinmodificar}
	\end{figure}
	Esta fila de la matriz quedaría de la siguiente manera.
	\begin{figure}[H]
		\centering
		\includegraphics[width=0.7\linewidth]{columanmodificada}
		\caption{}
		\label{fig:columanmodificada}
	\end{figure}
	
	
	 Por tanto finalmente obtendremos por cada dígito manuscrito una matriz 8x8 que contendrán un valor numérico entre [0,16]. Esto es un total de 64 enteros por cada dígito analizado. La división de la matriz inicial en matrices mas pequeñas nos asegura que el tamaño del problema se mucho menor al reducir el numero de valores por cada muestra y que al tener en cuenta matrices de 4x4 para dar un valor evitamos muchas invarianzas a pequeñas distorsiones que se podrían dar si usáramos directamente la matriz de 32x32. 
	
	Las clases para los dígitos vienen dada por los números naturales de un único dígito ([0-9]), teniendo un total de 10 posibles clases.
	
	La base de datos seleccionada ya nos da la partición de train y test con el siguiente numero de instancias y participantes.
	
	\begin{table}[htbp]
		\begin{center}
			\begin{tabular}{|l|l|l|}
				\hline
				Tipo & Nº Participantes & Nº instancias \\
				\hline
				Train & 30 & 3823\\ \hline
				Text & 13 & 1797\\
				 \hline
			\end{tabular}
		\end{center}
	\end{table}

	La proporción de cada clase es muy parecida tanto en el train como en el text con una diferencia como máximo en el conjunto de entrenamiento de 13 instancias entre la clase que mas tiene y la que menos. En el caso del test la diferencia máxima es de 9 instancias. 
	
		\begin{table}[htbp]
		\begin{center}
			\begin{tabular}{|l|l|l|}
				\hline
				Clase & Nº instancias train & Nº instancias test\\
				\hline
				0 & 376 & 178\\ 
				\hline
				1 & 389 & 182\\ 
				\hline
				2 & 380 & 177\\ 
				\hline
				3 & 389 & 183\\ 
				\hline
				4 & 387 & 181\\ 
				\hline
				5 & 376 & 182\\ 
				\hline
				6 & 377 & 181\\ 
				\hline
				7 & 387 & 179\\ 
				\hline
				8 & 380 & 174\\ 
				\hline
				9 & 382 & 180\\ 
				\hline
			\end{tabular}
		\end{center}
	\end{table}
	\newpage
	
	\subsection{Preprocesado de datos}
	En este caso el he realizado una normalización muy sencilla, al saber que los datos están en el rango [0sklearn.preprocessing.PolynomialFeatures
	
	-16], solo tenemos que dividir los datos entre 16.
	
	También se ha realizado una eliminación de variables que no aportan al problema. Estas variables son aquellas en cuya columna los datos tengan una varianza menor a 0 en este caso(todas las variables que solo tienen un único valor en todas las muestras.). Para esto he utilizado la función de VarianceThreshold de sklearn.feature\_selection.
	Esto nos ahorra 2 variables que tienen una varianza de 0. Estas partes de la matriz nunca han sido utilizadas para ningún numero.
	
	Para esto utilizo la siguiente función:
	\begin{lstlisting}
def eliminarDatosVarianza(train_x,train_y,limite):
	row_train = np.size(train_X,0)
	
	datos = np.concatenate((train_X, test_X), axis=0)
	
	selector = VarianceThreshold(limite)
	datos_procesados = selector.fit_transform(datos)
	
	train = datos_procesados[:row_train, :]
	test = datos_procesados[row_train:, :]
	return train,test
	\end{lstlisting}
	
A continuación vamos a añadir nueva información que nos ayude a clasificar, para esto uso la librería sklearn.preprocessing.PolynomialFeatures con el parámetro de grado 2. El código de la función seria el siguiente.
\begin{lstlisting}
def anadirInformacionPolinomial(train_X, test_X, grado = 2):
	poly = PolynomialFeatures(grado)
	train_X = poly.fit_transform(train_X)
	test_X = poly.fit_transform(test_X)
	
	return train_X, test_X
\end{lstlisting}

Esto nos añadirá nueva información de la siguiente manera. Si partimos de una muestra con [a,b] nos daría $[1,a,b,a^2,ab,b^2]$. En este caso he optado por elegir 2 porque con 4 la memoria se desborda al añadir demasiada información y con 3 no me mejoro el problema.

\subsection{Selección de clase de funciones a usar.}

El problema al que nos enfrentamos es un problema de clasificación. Vamos a usar una función lineal para solucionar este problema. Al ser clasificación y tener mas de dos etiquetas este problema no puede ser solucionado con una función lineal unicamente. Para esto utilizaremos la función lineal enfrentando una clase a todas las demás(one vs rest). 

Vamos a poner un pequeño ejemplo con tres clases para ver como funcionaria. Como se ve en la siguiente imagen es imposible dividir las clases con una única linea. 
\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\linewidth]{screenshot002}
	\caption{Conjunto de clases}
	\label{fig:screenshot002}
\end{figure}

En las siguientes imágenes se ve como enfrentamos una clase a las otras dos de forma que si se puede conseguir una separación mediante una función lineal.



\begin{figure}[H]
	\centering
	\subfloat[Triangulos]{
		\label{f:gato}
		\includegraphics[width=0.3\textwidth]{screenshot001}}
	\subfloat[Cuadrados]{
		\label{f:tigre}
		\includegraphics[width=0.3\textwidth]{screenshot004}}
	\subfloat[Cruces]{
		\label{f:conejo}
		\includegraphics[width=0.3\textwidth]{screenshot005}}
	\caption{División mediante one vs rest}
\end{figure}

Por tanto nos quedaremos con las funciones lineales para este problema.
 
\subsection{Definición de training, validación y test.}
En este caso los datos vienen divididos ya en train y test. En el train se tienen 40 personas y el test 13. Si somos capaces de conseguir un buen $E_{out}$, estaremos consiguiendo que sea capaz de reconocer los números sin tener en cuenta la forma de escribir de cada participante. Esto me parece la mejor opción y no he realizado ninguna modificación en este apartado.

\subsection{Necesidad de regularización}
Como se explico en teoría la regularización nunca viene mal para eliminar un poco de sobreajuste de nuestro modelo. En este caso he utilizado la regularización l1 (usa el valor absoluto) puesto después de varias pruebas me ha dado mejores resultados que l2(usa pesos al cuadrado). En este caso la diferencia es muy pequeña llegando a alrededor de un 1\%. Pero al ser también mas eficiente y rápida la regularización l1 he terminado optando por esta.

\subsection{Definición del modelos a usar y sus parámetros}
Vamos a utilizar dos algoritmos que utilizan funciones lineales. Uno sera regresión logistica y el otro perceptron. Los dos se basan en one vs rest(ovr) para resolver problemas multiclase.
\begin{enumerate}
	\item{Perceptron}: En este caso es el mas sencillo de los dos puesto que solo tenemos que ajustar tres parametros sencillos de entender. Usaremos la implementación de la librería sklearn.linear\_model.Perceptron
	\begin{enumerate}		
		\item{Umbral de parada:} Indicara cuando tengamos un error menor al indicado pararemos el perceptron.
		\item{Numero de iteraciones sin cambio:} Como el propio nombre indica cuando se realizen un numero de iteraciones en las que no conseguimos mejorar, el perceptron parara la ejecución.
		\item{Numero de iteraciones máxima:} En este caso sera en numero máximo de iteraciones que el perceptron  podrá realizar si no decide parar antes por alguna de las dos variables explicadas anteriormente.
	\end{enumerate}
	El perceptron intentara separar una clase del resto mediante un hyperplano. 
	
	\item{Regresión logística:} En este caso es tenemos los mismos parámetros que el perceptron solo tenemos dos parámetros que coinciden con los dados para el perceptron.
	\begin{enumerate}		
		\item{Umbral de parada:} Indicara cuando tengamos un error menor al indicado pararemos el perceptron.
		\item{Numero de iteraciones máxima:} En este caso sera en numero máximo de iteraciones podrá realizar si no decide parar antes por el umbral de parada.
	\end{enumerate}
	Regresión lineal intenta estimar la probabilidad de que pertenezca a una de las clases o al resto. Requiere grandes tamaños de datos y es muy eficiente y no requiere grandes recursos computacionales.
\end{enumerate}

\subsection{Selección y ajuste del modelo final}
Los datos medidos para los dos algoritmos con los parametros por defecto dados por la librería sklearn son los siguientes.
	\begin{table}[H]
		\begin{center}
			\begin{tabular}{|l|l|l|}
				\hline
				Algoritmo & Tiempo & Eout\\
				\hline
				Perceptron & 0.6093 & 4.0066\%\\ 
				\hline
				Regresión logística & 4.9787 & 2.5041\%\\  
				\hline
			\end{tabular}
		\end{center}
	\end{table}
El ajuste con regresión logística es un 1.5\% mejor aunque el perceptron es mas rápido que regresión logística. En este caso voy a optar por elegir el modelo de regresión logística para tratar de bajar el Eout por debajo del 2\%. Realizo esta selección para intentar mejorar el 98.00\% tasa de acierto que consigue k-nn con k=1 en estos datos. La tasa de acierto de k-nn viene especificada en el fichero optdigits.name del dataset. Los resultados que muestra son los siguientes.
\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\linewidth]{screenshot006}
\end{figure}
 
\subsection{Métrica usada}
La métrica usada en este caso es la tasa de acierto(Accuracy) que se basa en calcular el numero de aciertos totales tenidos entre el total de muestras. 


$$
Accuracy=\frac{Numero\ correcto\ de\ prediciones}{Numero\ total\ de\ predicciones}
$$
Me he decidido por esta métrica porque lo importante en este problema es ser capaces de acertar el numero. Para esto lo mejor es ver si la predicción realizada por regresión logística acertó con la etiqueta dada para esa entrada.

\subsection{Estimación del error Eout}
En este apartado vamos a ver cuanto he conseguido mejorar los datos dados por la regresión logística con los parámetros por defecto del algoritmo dado por sklearn.
En este caso me centre en mejorar mediante la regularización. Comparando si para nuestro problema cual es el parámetro C mejor. Este parámetro nos fuerza a regularizar de forma mas fuerte conforme mas bajo sea. 
\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\linewidth]{screenshot007}
\end{figure}
Como se ve en la grafica a partir  de 300 en c empezamos a sobrepasar el 98\% de tasa de acierto que conseguía el k-nn con k = 1.

Con el parámetro 500 obtengo un Eout 1.8363939899833093\%.
Para esto el parámetro umbral de parada lo asigno a $1e-3$ y las iteraciones máximas a 100.

\subsection{Discutir y justificar la calidad del modelo obtenido.}
El modelo encontrado me parece muy bueno siendo capaz de superar el 98\% de acierto y con un tiempo de poco mas de 2.7 segundos mejorando también el tiempo que nos dio por defecto en las pruebas anteriores que fue de 5 segundos.
Vamos a mostrar una matriz de confusión para ver los resultados.
\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\linewidth]{screenshot008}

\end{figure}

Como se ve la diagonal es la que tiene el peso de los aciertos y fuera de esta apenas hay un par de valores en los que nuestro algoritmo falla. Estos valores grises donde falla nos están diciendo que confundimos en algunos casos los 8 con 1 y los 7 con 9. 



\section{Airfoil self noise}
Los datos constan de 1503 casos, cada uno con 6 atributos obtenidos de una serie de pruebas aerodinámicas y acústicas de secciones de aspas aerodinámicas de dos y tres dimensiones realizadas en un túnel de viento con un revestimiento anecoico para absorber y atenuar el sonido. El conjunto contiene 6 variables. 




\end{document}

